import cv2
import os
import numpy as np

# Path to the face dataset
dataset_path = r"C:\Users\Vasu\Downloads\Real-time-Attendance-Management-System-using-Deep-Learning-Techniques-main\face_dataset"
recognizer = cv2.face.LBPHFaceRecognizer_create()

# List to hold face images and corresponding labels
faces = []
labels = []

# List of names (to map the labels back to names)
names = {}

# Function to load images and labels
def load_images_and_labels():
    label = 0
    for person_name in os.listdir(dataset_path):
        person_path = os.path.join(dataset_path, person_name)
        
        if os.path.isdir(person_path):
            names[label] = person_name  # Map label to person name
            
            for image_name in os.listdir(person_path):
                if image_name.endswith(".jpg"):
                    image_path = os.path.join(person_path, image_name)
                    
                    # Read image and convert to grayscale
                    gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                    
                    # Detect faces in the image
                    face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
                    faces_detected = face_detector.detectMultiScale(gray_image, 1.3, 5)
                    
                    for (x, y, w, h) in faces_detected:
                        face = gray_image[y:y + h, x:x + w]
                        faces.append(face)
                        labels.append(label)
            
            label += 1  # Increment label for next person

# Load images and labels
load_images_and_labels()

# Train the model using the faces and labels
recognizer.train(faces, np.array(labels))
recognizer.save("face_trainer.yml")
print("[INFO] Model trained and saved as 'face_trainer.yml'.")

# Start the webcam for real-time face recognition
cap = cv2.VideoCapture(0)
face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the frame
    faces_in_frame = face_detector.detectMultiScale(gray, 1.3, 5)
    
    for (x, y, w, h) in faces_in_frame:
        face = gray[y:y + h, x:x + w]
        
        # Predict the label of the face
        label, confidence = recognizer.predict(face)
        
        # Display the name if recognized, otherwise display 'Unknown'
        if confidence < 100:
            name = names[label]
        else:
            name = "Unknown"
        
        # Draw rectangle around face and display the name
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)
    
    # Show the video feed with face detection and name
    cv2.imshow("Face Recognition", frame)
    
    # Break the loop if 'ESC' key is pressed
    if cv2.waitKey(1) & 0xFF == 27:
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()
